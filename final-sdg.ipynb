{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-09-14T08:46:05.056828Z","iopub.status.busy":"2022-09-14T08:46:05.056400Z","iopub.status.idle":"2022-09-14T08:46:07.062150Z","shell.execute_reply":"2022-09-14T08:46:07.060947Z","shell.execute_reply.started":"2022-09-14T08:46:05.056734Z"},"trusted":true},"outputs":[],"source":["import re\n","import subprocess\n","import glob\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer "]},{"cell_type":"markdown","metadata":{},"source":["# Defining file paths"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.064885Z","iopub.status.busy":"2022-09-14T08:46:07.064535Z","iopub.status.idle":"2022-09-14T08:46:07.074487Z","shell.execute_reply":"2022-09-14T08:46:07.073209Z","shell.execute_reply.started":"2022-09-14T08:46:07.064850Z"},"trusted":true},"outputs":[],"source":["keywordsFile = \"../input/sdgs-keywords/terms.txt\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.077084Z","iopub.status.busy":"2022-09-14T08:46:07.076385Z","iopub.status.idle":"2022-09-14T08:46:07.093599Z","shell.execute_reply":"2022-09-14T08:46:07.092415Z","shell.execute_reply.started":"2022-09-14T08:46:07.077035Z"},"trusted":true},"outputs":[],"source":["filePathResultsCSV = './CSV/'\n","filePathResultsFigs = './figs/'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.095448Z","iopub.status.busy":"2022-09-14T08:46:07.095113Z","iopub.status.idle":"2022-09-14T08:46:07.111494Z","shell.execute_reply":"2022-09-14T08:46:07.110445Z","shell.execute_reply.started":"2022-09-14T08:46:07.095414Z"},"trusted":true},"outputs":[],"source":["filepathCSVSumNorm = filePathResultsCSV +'sumNorm.csv'\n","filepathCSVAverageNorm = filePathResultsCSV + 'averageNorm.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.115049Z","iopub.status.busy":"2022-09-14T08:46:07.114633Z","iopub.status.idle":"2022-09-14T08:46:07.128263Z","shell.execute_reply":"2022-09-14T08:46:07.127060Z","shell.execute_reply.started":"2022-09-14T08:46:07.115011Z"},"trusted":true},"outputs":[],"source":["filepathHMSumNorm = filePathResultsFigs + 'sumNorm.png'\n","filepathHMAverageNorm =filePathResultsFigs +'averageNorm.png'"]},{"cell_type":"markdown","metadata":{},"source":["# Housekeeping between runs\n","\n","Deletes all output between the runs; Kaggle requires this."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.133386Z","iopub.status.busy":"2022-09-14T08:46:07.133036Z","iopub.status.idle":"2022-09-14T08:46:07.145868Z","shell.execute_reply":"2022-09-14T08:46:07.144558Z","shell.execute_reply.started":"2022-09-14T08:46:07.133356Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil \n","try:\n","    shutil.rmtree(filePathResultsCSV)\n","    shutil.rmtree(filePathResultsFigs)\n","except:\n","    print(\"Directories missing\")\n","os.mkdir(filePathResultsCSV)\n","os.mkdir(filePathResultsFigs)"]},{"cell_type":"markdown","metadata":{},"source":["# Lemming and Stemming Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.149622Z","iopub.status.busy":"2022-09-14T08:46:07.149069Z","iopub.status.idle":"2022-09-14T08:46:07.158826Z","shell.execute_reply":"2022-09-14T08:46:07.157987Z","shell.execute_reply.started":"2022-09-14T08:46:07.149561Z"},"trusted":true},"outputs":[],"source":["def termsTokenizer(str_input):\n","    blob = TextBlob(str_input.lower())\n","    tokens = blob.words\n","    words = [token.stem() for token in tokens]\n","    #words = [token.lem() for token in tokens]\n","    return words\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.160374Z","iopub.status.busy":"2022-09-14T08:46:07.160055Z","iopub.status.idle":"2022-09-14T08:46:07.175858Z","shell.execute_reply":"2022-09-14T08:46:07.174834Z","shell.execute_reply.started":"2022-09-14T08:46:07.160342Z"},"trusted":true},"outputs":[],"source":["def termsStemming(searchTerms):\n","    searchTermsStemmed = [None] * len(searchTerms)\n","    for i in range(len(searchTerms)):\n","        if (len(termsTokenizer(searchTerms[i])) == 1): #If only one word\n","            searchTermsStemmed[i] = termsTokenizer(searchTerms[i])[0]\n","        else:\n","            searchTermsStemmed[i] = str(termsTokenizer(searchTerms[i])[0]) + \" \" + termsTokenizer(searchTerms[i])[1]\n","    return searchTermsStemmed"]},{"cell_type":"markdown","metadata":{},"source":["# Search Terms Extraction"]},{"cell_type":"markdown","metadata":{},"source":["The search terms are given as a LaTeX table saved in a plaintext file format. We need to separate the search terms:\n","> Term's category code & Term's category name & search term foo, bar \\\\\\\n","\n","For example:\n","> G9 & Industry, Innovation, Infrastructure & technological innovations \\\\\\"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.178151Z","iopub.status.busy":"2022-09-14T08:46:07.177795Z","iopub.status.idle":"2022-09-14T08:46:07.191095Z","shell.execute_reply":"2022-09-14T08:46:07.190139Z","shell.execute_reply.started":"2022-09-14T08:46:07.178119Z"},"trusted":true},"outputs":[],"source":["def termsSeperator(rawTerms):\n","    termsArray = []\n","    for term in rawTerms:\n","        if term is rawTerms[len(rawTerms)-1]: # quick fix for the '\\\\\\\\' chars at the end\n","            term = term.replace(\"\\\\\\\\\", \"\") \n","            term = term.replace(\"\\\\\", \"\") \n","        term = term.strip()\n","        termsArray.append(term)\n","    return termsArray"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.192660Z","iopub.status.busy":"2022-09-14T08:46:07.192219Z","iopub.status.idle":"2022-09-14T08:46:07.209567Z","shell.execute_reply":"2022-09-14T08:46:07.208578Z","shell.execute_reply.started":"2022-09-14T08:46:07.192630Z"},"trusted":true},"outputs":[],"source":["def pdfFiletypeTrimmer(filename):\n","    return filename.replace(\".pdf\",\"\")"]},{"cell_type":"markdown","metadata":{},"source":["# TFIDF Vectors"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.211735Z","iopub.status.busy":"2022-09-14T08:46:07.211092Z","iopub.status.idle":"2022-09-14T08:46:07.228668Z","shell.execute_reply":"2022-09-14T08:46:07.227439Z","shell.execute_reply.started":"2022-09-14T08:46:07.211688Z"},"trusted":true},"outputs":[],"source":["def getTIDFVectorsAsArray(tfidf_vectorizer_vectors):\n","    return tfidf_vectorizer_vectors.toarray()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.231009Z","iopub.status.busy":"2022-09-14T08:46:07.230513Z","iopub.status.idle":"2022-09-14T08:46:07.244226Z","shell.execute_reply":"2022-09-14T08:46:07.242959Z","shell.execute_reply.started":"2022-09-14T08:46:07.230933Z"},"trusted":true},"outputs":[],"source":["def getTDIDFVector(vectors,index):\n","    return getTIDFVectorsAsArray(vectors)[index]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.246452Z","iopub.status.busy":"2022-09-14T08:46:07.245933Z","iopub.status.idle":"2022-09-14T08:46:07.260640Z","shell.execute_reply":"2022-09-14T08:46:07.259475Z","shell.execute_reply.started":"2022-09-14T08:46:07.246406Z"},"trusted":true},"outputs":[],"source":["def mapTFIDFLabelsValues(vectorizer, vectors, index):\n","    return dict(zip(vectorizer.get_feature_names(), getTDIDFVector(vectors,index)))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.263868Z","iopub.status.busy":"2022-09-14T08:46:07.263526Z","iopub.status.idle":"2022-09-14T08:46:07.274401Z","shell.execute_reply":"2022-09-14T08:46:07.273211Z","shell.execute_reply.started":"2022-09-14T08:46:07.263835Z"},"trusted":true},"outputs":[],"source":["def getTDIDFMatrix(tfidf_vectorizer_vectors, i):\n","    return tfidf_vectorizer_vectors[i] .T.todense()"]},{"cell_type":"markdown","metadata":{},"source":["# Util Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.276845Z","iopub.status.busy":"2022-09-14T08:46:07.276359Z","iopub.status.idle":"2022-09-14T08:46:07.290559Z","shell.execute_reply":"2022-09-14T08:46:07.289312Z","shell.execute_reply.started":"2022-09-14T08:46:07.276810Z"},"trusted":true},"outputs":[],"source":["def getDFWithSearchTerms(df, searchTerms):\n","    return df.loc[df.index.isin(searchTermsStemmed)]  "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.292640Z","iopub.status.busy":"2022-09-14T08:46:07.292065Z","iopub.status.idle":"2022-09-14T08:46:07.305243Z","shell.execute_reply":"2022-09-14T08:46:07.304052Z","shell.execute_reply.started":"2022-09-14T08:46:07.292585Z"},"trusted":true},"outputs":[],"source":["def filterDictionary(dictionary, filterTerm):\n","    return { k:v for k, v in dictionary.items() if k in filterTerm}"]},{"cell_type":"markdown","metadata":{},"source":["# Main Program"]},{"cell_type":"markdown","metadata":{},"source":["Init lematizer and stemmers. Also, load the the stopwords to be used."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.307017Z","iopub.status.busy":"2022-09-14T08:46:07.306527Z","iopub.status.idle":"2022-09-14T08:46:07.326788Z","shell.execute_reply":"2022-09-14T08:46:07.325795Z","shell.execute_reply.started":"2022-09-14T08:46:07.306957Z"},"trusted":true},"outputs":[],"source":["stopWords = set(stopwords.words('english'))"]},{"cell_type":"markdown","metadata":{},"source":["## Corpus Reading & Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.328766Z","iopub.status.busy":"2022-09-14T08:46:07.328327Z","iopub.status.idle":"2022-09-14T08:46:07.341717Z","shell.execute_reply":"2022-09-14T08:46:07.340477Z","shell.execute_reply.started":"2022-09-14T08:46:07.328733Z"},"trusted":true},"outputs":[],"source":["pdfFiles = glob.glob(\"../input/policyguidelines/*.pdf\")\n","pdfFiles += glob.glob(\"../input/policyguidelines/*.PDF\")"]},{"cell_type":"markdown","metadata":{},"source":["Sorting based on file name. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.343900Z","iopub.status.busy":"2022-09-14T08:46:07.343455Z","iopub.status.idle":"2022-09-14T08:46:07.349184Z","shell.execute_reply":"2022-09-14T08:46:07.348303Z","shell.execute_reply.started":"2022-09-14T08:46:07.343867Z"},"trusted":true},"outputs":[],"source":["pdfFiles = sorted(pdfFiles)\n","print(pdfFiles)"]},{"cell_type":"markdown","metadata":{},"source":["Create the corpus by converting PDFs into plaintext"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:07.350824Z","iopub.status.busy":"2022-09-14T08:46:07.350361Z","iopub.status.idle":"2022-09-14T08:46:11.405240Z","shell.execute_reply":"2022-09-14T08:46:11.403740Z","shell.execute_reply.started":"2022-09-14T08:46:07.350782Z"},"trusted":true},"outputs":[],"source":["corpus = {}\n","for pdfPath in pdfFiles:\n","    command  = ['pdftotext','-layout', pdfPath, '-']\n","    output   =  subprocess.check_output(command).decode()\n","    pdfName = pdfPath.split(\"/\")\n","    pdfName = pdfName[len(pdfName)-1]\n","    corpus[pdfFiletypeTrimmer(pdfName)] = output"]},{"cell_type":"markdown","metadata":{},"source":["Remove whitespaces and seperators."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:11.407640Z","iopub.status.busy":"2022-09-14T08:46:11.407276Z","iopub.status.idle":"2022-09-14T08:46:11.672370Z","shell.execute_reply":"2022-09-14T08:46:11.671404Z","shell.execute_reply.started":"2022-09-14T08:46:11.407604Z"},"trusted":true},"outputs":[],"source":["for key, value in corpus.items():    \n","    corpus[key] = value.lower()\n","    corpus[key] = re.sub(r'\\W',' ',value)\n","    corpus[key] = re.sub(r'\\s+',' ',value)"]},{"cell_type":"markdown","metadata":{},"source":["## Reading our search terms"]},{"cell_type":"markdown","metadata":{},"source":["Import and process our SDG-related terms."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:11.674221Z","iopub.status.busy":"2022-09-14T08:46:11.673687Z","iopub.status.idle":"2022-09-14T08:46:11.685295Z","shell.execute_reply":"2022-09-14T08:46:11.684105Z","shell.execute_reply.started":"2022-09-14T08:46:11.674188Z"},"trusted":true},"outputs":[],"source":["searchCategoriesDic = {}\n","searchDic = {}\n","\n","with open(keywordsFile, encoding='utf8') as termsFile:\n","    for rawLine in termsFile:\n","        rawLine = rawLine.split(\"&\")\n","        categoryCode = rawLine[0].replace(\" \",\"\")#assuming that the file is formatted properly :D\n","        name = rawLine[1] \n","        rawTerms = rawLine[2].split(\",\")\n","        searchCategoriesDic[categoryCode] = name\n","        searchDic[categoryCode] = termsSeperator(rawTerms)\n","        "]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:11.687474Z","iopub.status.busy":"2022-09-14T08:46:11.687063Z","iopub.status.idle":"2022-09-14T08:46:11.704564Z","shell.execute_reply":"2022-09-14T08:46:11.703522Z","shell.execute_reply.started":"2022-09-14T08:46:11.687431Z"},"trusted":true},"outputs":[],"source":["for key, value in searchDic.items():\n","    searchCategoriesDic[key].replace(\"  \",\"\")\n","    searchDic[key] = searchDic[key] + searchCategoriesDic[key].split(\", \") \n","    print(searchDic[key])"]},{"cell_type":"markdown","metadata":{},"source":["## Constructing our TD-IDF Matrix"]},{"cell_type":"markdown","metadata":{},"source":["Init the vectorizer and vectors, the former contains all the labels and the other the values."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:11.706333Z","iopub.status.busy":"2022-09-14T08:46:11.705849Z","iopub.status.idle":"2022-09-14T08:46:20.261314Z","shell.execute_reply":"2022-09-14T08:46:20.260146Z","shell.execute_reply.started":"2022-09-14T08:46:11.706300Z"},"trusted":true},"outputs":[],"source":["tfidf_vectorizer=TfidfVectorizer(use_idf=True, analyzer='word', ngram_range=(1,2), min_df = 0, stop_words = 'english', tokenizer=termsTokenizer)\n","tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(corpus.values()) # just send in all your docs here "]},{"cell_type":"markdown","metadata":{},"source":["Mapping labels to values and storing them in our `tfidfDic` dictionary. The structure is: `{<corpusFileName> : {<searchCategoryCode> : <searchTerms>}}`\n","\n","Note: The `searchTerms` are stemmed.If `filterDictionary(tfidfValues,termsStemming(terms))` returns an empty dictionary, then there are no values!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:20.263154Z","iopub.status.busy":"2022-09-14T08:46:20.262794Z","iopub.status.idle":"2022-09-14T08:46:27.361917Z","shell.execute_reply":"2022-09-14T08:46:27.360822Z","shell.execute_reply.started":"2022-09-14T08:46:20.263121Z"},"trusted":true},"outputs":[],"source":["tfidfDic={}\n","for i, corpusName in enumerate(corpus):\n","    tfidfValues = dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer_vectors.toarray()[i]))\n","    tempDic = {}\n","    print(corpusName)\n","    for code, terms in searchDic.items():    \n","        tempDic[code] = filterDictionary(tfidfValues,termsStemming(terms))\n","        print(tempDic[code])\n","    tfidfDic[corpusName] = tempDic\n","    "]},{"cell_type":"markdown","metadata":{},"source":["## Results gathering"]},{"cell_type":"markdown","metadata":{},"source":["Produces the results for each keyword individually."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:27.363572Z","iopub.status.busy":"2022-09-14T08:46:27.363233Z","iopub.status.idle":"2022-09-14T08:46:27.459046Z","shell.execute_reply":"2022-09-14T08:46:27.457854Z","shell.execute_reply.started":"2022-09-14T08:46:27.363540Z"},"trusted":true},"outputs":[],"source":["dfsPerFile = []\n","for fileName, searchTermsDic in tfidfDic.items():\n","    dfsSearchCategory = []\n","    for searchCategory in searchTermsDic.values():\n","        df = pd.DataFrame.from_dict(searchCategory, columns=[fileName], orient='index')\n","        dfsSearchCategory.append(df)\n","    categoryDF = pd.concat(dfsSearchCategory)\n","    dfsPerFile.append(categoryDF)\n","\n","if len(dfsPerFile) > 1:\n","    resultsDF = pd.concat(dfsPerFile, axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["Results aggregated per sum per category and average per category"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:27.460694Z","iopub.status.busy":"2022-09-14T08:46:27.460363Z","iopub.status.idle":"2022-09-14T08:46:27.482940Z","shell.execute_reply":"2022-09-14T08:46:27.482001Z","shell.execute_reply.started":"2022-09-14T08:46:27.460660Z"},"trusted":true},"outputs":[],"source":["categorySumResults = {}\n","categoryAverageResults = {}\n","fileSumDFArray = []\n","fileAverageDFArray = []\n","\n","for fileName, searchTermsDic in tfidfDic.items():\n","    for categoryCode, searchCategory in searchTermsDic.items():\n","        average = 0\n","        currentSum = 0\n","        for tdidfValue in searchCategory.values():\n","            currentSum = tdidfValue + currentSum\n","        if len(searchCategory.values())!= 0:\n","            average = currentSum / len(searchCategory.values())   \n","        else:\n","            average = 0\n","        categorySumResults[categoryCode] = currentSum\n","        categoryAverageResults[categoryCode] = average\n","    fileSumDFArray.append(pd.DataFrame.from_dict(categorySumResults, columns=[fileName], orient='index'))\n","    fileAverageDFArray.append(pd.DataFrame.from_dict(categoryAverageResults, columns=[fileName], orient='index'))\n","\n","if len(fileSumDFArray) > 1:\n","    sumDF = pd.concat(fileSumDFArray, axis=1)\n","if len(fileAverageDFArray) > 1:\n","    averageDF = pd.concat(fileAverageDFArray, axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["**Normalisation** of the sum and average values by a factor of 100:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:27.485081Z","iopub.status.busy":"2022-09-14T08:46:27.484589Z","iopub.status.idle":"2022-09-14T08:46:27.541175Z","shell.execute_reply":"2022-09-14T08:46:27.540256Z","shell.execute_reply.started":"2022-09-14T08:46:27.485034Z"},"trusted":true},"outputs":[],"source":["if not sumDF.empty:\n","    normalisedSumDF = sumDF\n","    normalisedSumDF[normalisedSumDF.select_dtypes(include=['number']).columns] *= 100    \n","if not averageDF.empty:\n","    normalisedAverageDF = averageDF\n","    normalisedAverageDF[normalisedAverageDF.select_dtypes(include=['number']).columns] *= 100"]},{"cell_type":"markdown","metadata":{},"source":["## Export Results"]},{"cell_type":"markdown","metadata":{},"source":["### Export to CSV"]},{"cell_type":"markdown","metadata":{},"source":["Create the csv with the sum value."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:27.582218Z","iopub.status.busy":"2022-09-14T08:46:27.581839Z","iopub.status.idle":"2022-09-14T08:46:27.594012Z","shell.execute_reply":"2022-09-14T08:46:27.593044Z","shell.execute_reply.started":"2022-09-14T08:46:27.582186Z"},"trusted":true},"outputs":[],"source":["if not normalisedSumDF.empty:\n","    normalisedSumDF.to_csv(filepathCSVSumNorm, index=True, header=True)"]},{"cell_type":"markdown","metadata":{},"source":["Create the csv with the average value."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:27.596351Z","iopub.status.busy":"2022-09-14T08:46:27.595709Z","iopub.status.idle":"2022-09-14T08:46:27.610125Z","shell.execute_reply":"2022-09-14T08:46:27.609142Z","shell.execute_reply.started":"2022-09-14T08:46:27.596311Z"},"trusted":true},"outputs":[],"source":["if not normalisedAverageDF.empty:\n","    normalisedAverageDF.to_csv(filepathCSVAverageNorm, index=True, header=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Export to Heatmap"]},{"cell_type":"markdown","metadata":{},"source":["Create the heatmap with the sum value."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:27.640426Z","iopub.status.busy":"2022-09-14T08:46:27.640103Z","iopub.status.idle":"2022-09-14T08:46:30.804107Z","shell.execute_reply":"2022-09-14T08:46:30.802948Z","shell.execute_reply.started":"2022-09-14T08:46:27.640396Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize = (15,8))\n","\n","sns.heatmap(normalisedSumDF, annot=True,  cmap=\"YlGnBu\")\n","plt.savefig(filepathHMSumNorm, dpi=300)"]},{"cell_type":"markdown","metadata":{},"source":["Create the heatmap with the average value."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-14T08:46:30.805820Z","iopub.status.busy":"2022-09-14T08:46:30.805503Z","iopub.status.idle":"2022-09-14T08:46:33.839624Z","shell.execute_reply":"2022-09-14T08:46:33.838575Z","shell.execute_reply.started":"2022-09-14T08:46:30.805781Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize = (15,8))\n","\n","sns.heatmap(normalisedAverageDF, annot=True, cmap=\"YlGnBu\")\n","plt.savefig(filepathHMAverageNorm, dpi=300)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
